\documentclass[answers,12pt,addpoints]{exam}
\usepackage{import}

\import{C:/Users/prana/OneDrive/Desktop/MathNotes}{style.tex}

% Header
\newcommand{\name}{Pranav Tikkawar}
\newcommand{\course}{01:640:481}
\newcommand{\assignment}{Lecture 11}
\author{\name}
\title{\course \ - \assignment}

\begin{document}
\maketitle

\begin{questions}
    \question Question 1. \\
    We saw in class that for $U [0, a]$, if we use $Y_n$ (sample max) as an estimator for a, it is biased because $E[Yn] = n/n+1 \cdot a $. Keeping in
mind properties of expectation, modify $Y_n$ so we get an unbiased estimator for $a$.
What is desirable in an unbiased estimator: High variance or low variance?
\begin{solution}
    We can use $Y_n' = \frac{n+1}{n}Y_n$ as an unbiased estimator for a. This is because $E[Y_n'] = a$.\\
Additionally we would want a low variance for our unbiased estimator as it would lead to more of our values to group towards the mean.
\end{solution}
    \question Question 2 \\
    Suppose you are dealing with a population with pdf $\alpha x^{\alpha-1}$, $0 < x < 1$ with a parameter $\alpha > 0$ that is unknown.
    An observation of 3 independent random variables from this population came up as $x_1 = 0.2$, $x_2 = 0.4$, $x_3 = 0.3$. What is the
    estimated value of $\alpha$ using the maximum-likelihood idea of estimation?
    \begin{solution}
        To estimate $\alpha$ using the maximum-likelihood estimation (MLE), we first write down the likelihood function. Given the pdf $f(x; \alpha) = \alpha x^{\alpha-1}$, the likelihood function for the observed data $x_1, x_2, x_3$ is:
        \begin{align*}
        L(\alpha) &= \prod_{i=1}^{3} \alpha x_i^{\alpha-1} \\
        &= \alpha^3 \cdot x_1^{\alpha-1} \cdot x_2^{\alpha-1} \cdot x_3^{\alpha-1}\\ 
        &=\alpha^3 \cdot 0.2^{\alpha-1} \cdot 0.4^{\alpha-1} \cdot 0.3^{\alpha-1}\\
        &= \alpha^3 (.024)^{\alpha-1}
        \end{align*}
        Now the log likelihood function is:
        \begin{align*}
            \log L(\alpha) &= \log \alpha^3 + (\alpha-1) \log(.024)\\
            &= 3 \log \alpha + (\alpha-1) \log(.024)
        \end{align*}
        To find the MLE, we differentiate the log likelihood function with respect to $\alpha$ and set it to 0:
        \begin{align*}
            \frac{d}{d\alpha} \log L(\alpha) &= \frac{3}{\alpha} + \log(.024) = 0\\
            \implies \hat{\alpha_{MLE}} &= -\frac{3}{\log(.024)} 
        \end{align*}
        

        
    \end{solution}


\end{questions}
\end{document}